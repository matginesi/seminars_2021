{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FinalCNN_FaceMaskRecognition",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D61PSAg07AGG"
      },
      "source": [
        "# Face Cover Detection\n",
        "## Ginesi Matteo - 1832198 (ginesi.1832198@studenti.uniroma1.it)\n",
        "## Chitrada Govardhan - 1923585 (chitrada.1923585@studenti.uniroma1.it)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GnnMy4LDvldZ"
      },
      "source": [
        "# Google colab loading phase\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "from zipfile import ZipFile\n",
        "from tqdm import tqdm\n",
        "\n",
        "with ZipFile(file='/content/gdrive/MyDrive/new_data.zip') as zip_file:\n",
        "    for file in tqdm(iterable=zip_file.namelist(), total=len(zip_file.namelist())):\n",
        "        zip_file.extract(member=file)\n",
        "\n",
        "drive.flush_and_unmount()\n",
        "print(' :: Unzip done.\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RMvte9YmzOQ4"
      },
      "source": [
        "# Standard import"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "16KWJor044y7"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "from torchvision import datasets, transforms, models\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "from PIL import Image\n",
        "import warnings\n",
        "from tqdm import tqdm\n",
        "from torch import Tensor\n",
        "from torch.nn import functional\n",
        "import time\n",
        "import sys"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wnOM8ywHzSak"
      },
      "source": [
        "# Basic parameters for training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7iY4fv2D49uL"
      },
      "source": [
        "DATA_DIR = 'new_data'\n",
        "BATCH_SIZE = 32  # 32\n",
        "NUM_WORKERS = 32  # 12\n",
        "RESIZE_PARAM = 32  # 256\n",
        "EPOCHS = 10\n",
        "MODEL_NAME = 'FaceMaskDetectorCNN'  # 'CustomCNN'\n",
        "LEARNING_RATE = 0.001  # 0.0005\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print('PyTorch device in use: ', device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CCQDYoHHzYkX"
      },
      "source": [
        "# Our CNN custom"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "65Ch7odr4_hL"
      },
      "source": [
        "class FaceMaskDetectorCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(FaceMaskDetectorCNN, self).__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, padding=1)\n",
        "        self.conv2 = nn.Conv2d(16, 8, kernel_size=3, padding=1)\n",
        "        self.fc1 = nn.Linear(8 * 8 * 8, 32)\n",
        "        self.fc2 = nn.Linear(32, 3)\n",
        "\n",
        "    def forward(self, x: Tensor):\n",
        "        \"\"\" forward pass\n",
        "        \"\"\"\n",
        "        out = functional.max_pool2d(torch.tanh(self.conv1(x)), 2)\n",
        "        out = functional.max_pool2d(torch.tanh(self.conv2(out)), 2)\n",
        "        out = out.view(-1, 8 * 8 * 8)\n",
        "        out = torch.tanh(self.fc1(out))\n",
        "        out = self.fc2(out)\n",
        "        return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dvKPSVN-zgTF"
      },
      "source": [
        "# Loader transformations and splitting functions definition"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GErlF39D5BQi"
      },
      "source": [
        "def custom_loader(path):\n",
        "    with open(path, 'rb') as f:\n",
        "        img = Image.open(f)\n",
        "        return img.convert('RGB')\n",
        "\n",
        "\n",
        "train_transforms = transforms.Compose([\n",
        "    transforms.RandomResizedCrop(RESIZE_PARAM),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n",
        "test_transforms = transforms.Compose([\n",
        "    transforms.Resize(RESIZE_PARAM),\n",
        "    transforms.CenterCrop(RESIZE_PARAM),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "\n",
        "def load_split_train_test(datadir, valid_size=.2):\n",
        "    train_data = datasets.ImageFolder(\n",
        "        datadir,\n",
        "        transform=train_transforms,\n",
        "        loader=custom_loader)\n",
        "    test_data = datasets.ImageFolder(\n",
        "        datadir,\n",
        "        transform=test_transforms,\n",
        "        loader=custom_loader)\n",
        "\n",
        "    num_train = len(train_data)\n",
        "    indices = list(range(num_train))\n",
        "    split = int(np.floor(valid_size * num_train))\n",
        "    np.random.shuffle(indices)\n",
        "\n",
        "    train_idx, test_idx = indices[split:], indices[:split]\n",
        "    train_sampler = SubsetRandomSampler(train_idx)\n",
        "    test_sampler = SubsetRandomSampler(test_idx)\n",
        "    trainloader = torch.utils.data.DataLoader(\n",
        "        train_data,\n",
        "        sampler=train_sampler,\n",
        "        batch_size=BATCH_SIZE)\n",
        "    testloader = torch.utils.data.DataLoader(\n",
        "        test_data,\n",
        "        sampler=test_sampler,\n",
        "        batch_size=BATCH_SIZE)\n",
        "    return trainloader, testloader\n",
        "\n",
        "\n",
        "trainloader, testloader = load_split_train_test(DATA_DIR, .2)\n",
        "classes = trainloader.dataset.classes\n",
        "print(classes)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GdJM4o6ozp-C"
      },
      "source": [
        "# Model choice and parameter definitions, parallelism if enabled"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oAPmOp3_5DtM"
      },
      "source": [
        "if MODEL_NAME == 'ResNet50':\n",
        "    model = models.resnet50(pretrained=True)\n",
        "    # model.to(device)\n",
        "    # print(model)\n",
        "\n",
        "    for param in model.parameters():\n",
        "        param.requires_grad = False\n",
        "\n",
        "    model.fc = nn.Sequential(\n",
        "        nn.Linear(2048, 512),\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout(0.2),\n",
        "        nn.Linear(512, 10),\n",
        "        nn.LogSoftmax(dim=1))\n",
        "\n",
        "    criterion = nn.NLLLoss()\n",
        "    optimizer = optim.Adam(model.fc.parameters(), lr=LEARNING_RATE)\n",
        "    # model.to(device)\n",
        "elif MODEL_NAME == 'FaceMaskDetectorCNN':\n",
        "    model = FaceMaskDetectorCNN()\n",
        "    criterion = nn.NLLLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
        "    # model.to(device)\n",
        "\n",
        "if torch.cuda.device_count() > 1:\n",
        "    print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
        "    model = nn.DataParallel(model)\n",
        "model.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Op1025jwzyQb"
      },
      "source": [
        "# Training phase"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7DazT5QW5Foo"
      },
      "source": [
        "\n",
        "model.to(device)\n",
        "graph_training_loss, graph_valid_loss, graph_acc = [], [], []\n",
        "\n",
        "\n",
        "epochs = EPOCHS\n",
        "steps = 0\n",
        "running_loss = 0\n",
        "print_every = 10\n",
        "train_losses, test_losses = [], []\n",
        "total_accuracy = []\n",
        "\n",
        "print(' :: Training phase...', end='\\n')\n",
        "print(' Epochs: {}, test evaluation at every {} steps'.format(\n",
        "    epochs, print_every),\n",
        "    end='\\n\\n')\n",
        "sys.stdout.flush()\n",
        "\n",
        "since = time.time()\n",
        "for epoch in range(epochs):\n",
        "    for inputs, labels in tqdm(trainloader):\n",
        "        steps += 1\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        logps = model.forward(inputs)\n",
        "        loss = criterion(logps, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "\n",
        "        if steps % print_every == 0:\n",
        "            test_loss = 0\n",
        "            accuracy = 0\n",
        "            model.eval()\n",
        "            with torch.no_grad():\n",
        "                for inputs, labels in testloader:\n",
        "                    inputs = inputs.to(device)\n",
        "                    labels = labels.to(device)\n",
        "\n",
        "                logps = model.forward(inputs)\n",
        "                batch_loss = criterion(logps, labels)\n",
        "                test_loss += batch_loss.item()\n",
        "\n",
        "                ps = torch.exp(logps)\n",
        "                top_p, top_class = ps.topk(1, dim=1)\n",
        "                equals = top_class == labels.view(*top_class.shape)\n",
        "                accuracy += torch.mean(equals.type(torch.FloatTensor)).item()\n",
        "                total_accuracy.append(accuracy)\n",
        "\n",
        "            train_losses.append(running_loss / len(trainloader))\n",
        "            test_losses.append(test_loss / len(testloader))\n",
        "            \"\"\"\n",
        "            print(f\"\\nTest evaluation: Epoch {epoch + 1}/{epochs}\\t\"\n",
        "                    f\"Train loss: {running_loss / print_every:.3f}\\t \"\n",
        "                    f\"Test loss: {test_loss / len(testloader):.3f}\\t \"\n",
        "                    f\"Test accuracy: {accuracy / len(testloader):.3f}\")\n",
        "            \"\"\"\n",
        "            running_loss = 0\n",
        "            model.train()\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print('\\nEpoch: {}/{} in {:4.0f}:{:2.0f}  '.format(\n",
        "        epoch, epochs, time_elapsed // 60, time_elapsed % 60))\n",
        "    print('Training loss: {:.4f}\\tTest loss: {:.4f}\\tAccuracy: {:.4f}'.format(\n",
        "        sum(test_losses) / len(test_losses),\n",
        "        sum(train_losses) / len(train_losses),\n",
        "        sum(total_accuracy) / len(total_accuracy)\n",
        "    ))\n",
        "    graph_valid_loss.append(sum(test_losses) / len(test_losses))\n",
        "    graph_training_loss.append(sum(train_losses) / len(train_losses))\n",
        "    graph_acc.append(sum(total_accuracy) / len(total_accuracy))\n",
        "    sys.stdout.flush()\n",
        "\n",
        "time_elapsed = time.time() - since\n",
        "print('\\nTraining complete in {:.0f}h {:.0f}m {:.0f}s'.format(\n",
        "    time_elapsed // (60 * 60),\n",
        "    time_elapsed // 60,\n",
        "    time_elapsed % 60))\n",
        "\n",
        "torch.save(model, MODEL_NAME + '.pth')\n",
        "\n",
        "plt.plot(graph_training_loss, label='Training loss')\n",
        "plt.plot(graph_valid_loss, label='Validation loss')\n",
        "plt.plot(graph_acc, label='Accuracy')\n",
        "plt.legend(frameon=False)\n",
        "plt.savefig(MODEL_NAME + '_metrics.png')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}